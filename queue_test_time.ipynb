{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=2\n"
     ]
    }
   ],
   "source": [
    "%env OMP_NUM_THREADS=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmdet.core import get_classes\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.ops import RoIAlign, RoIPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'mmdetection/configs/icartoonface/fr50_lite_dcn_att_gn_scratch_icf_wf.py'\n",
    "checkpoint_file = 'work_dirs/fr50_lite_dcn_att_gn_scratch_icf_wf/latest.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImage(object):\n",
    "\n",
    "    def __call__(self, results):\n",
    "        if isinstance(results['img'], str):\n",
    "            results['filename'] = results['img']\n",
    "            results['ori_filename'] = results['img']\n",
    "        else:\n",
    "            results['filename'] = None\n",
    "            results['ori_filename'] = None\n",
    "        img = mmcv.imread(results['img'])\n",
    "        results['img'] = img\n",
    "        results['img_fields'] = ['img']\n",
    "        results['img_shape'] = img.shape\n",
    "        results['ori_shape'] = img.shape\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing loader\n",
    "def data_loader(model, img_q, data_q):\n",
    "    while True:\n",
    "        img = img_q.get()\n",
    "        cfg = model.cfg\n",
    "        device = next(model.parameters()).device  # model device\n",
    "        # build the data pipeline\n",
    "        test_pipeline = [LoadImage()] + cfg.data.test.pipeline[1:]\n",
    "        test_pipeline = Compose(test_pipeline)\n",
    "        # prepare data\n",
    "        data = dict(img=img)\n",
    "        data = test_pipeline(data)\n",
    "        data = collate([data], samples_per_gpu=1)\n",
    "        if next(model.parameters()).is_cuda:\n",
    "            # scatter to specified GPU\n",
    "            data = scatter(data, [device])[0]\n",
    "        else:\n",
    "            # Use torchvision ops for CPU mode instead\n",
    "            for m in model.modules():\n",
    "                if isinstance(m, (RoIPool, RoIAlign)):\n",
    "                    if not m.aligned:\n",
    "                        # aligned=False is not implemented on CPU\n",
    "                        # set use_torchvision on-the-fly\n",
    "                        m.use_torchvision = True\n",
    "            warnings.warn('We set use_torchvision=True in CPU mode.')\n",
    "            # just get the actual data from DataContainer\n",
    "            data['img_metas'] = data['img_metas'][0].data\n",
    "        \n",
    "        data_q.put(data)\n",
    "        img_q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo worker definition\n",
    "def single_inference_detector(model, data_q, result_q):\n",
    "    while True:\n",
    "        data  =data_q.get()\n",
    "         # forward the model\n",
    "        with torch.no_grad():\n",
    "            result = model(return_loss=False, rescale=True, **data)\n",
    "        \n",
    "        result_q.put(result)\n",
    "    \n",
    "        data_q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corcurrent number of gpu workers\n",
    "n_corcurrent = 4\n",
    "\n",
    "# corcurrent models\n",
    "models = [init_detector(config_file, checkpoint_file, device='cuda:0') for _ in range(n_corcurrent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate same image for testing\n",
    "img = np.random.randint(0, 255, size=(1920, 1080, 3)).astype(np.uint8)\n",
    "# img = np.random.randint(0, 255, size=(1333, 800, 3)).astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "n_imgs= 2000\n",
    "\n",
    "img_q= Queue()\n",
    "data_q = Queue(n_corcurrent * 2)\n",
    "result_q = Queue()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# put imgs into queue\n",
    "for _ in range(n_imgs):\n",
    "    img_q.put(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi thread data loader\n",
    "n_data_loader = n_corcurrent * 2\n",
    "data_workers = [Thread(target=data_loader, args=[models[0], img_q, data_q]) for _ in range(n_data_loader)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# warm up\n",
    "# warmup = 5\n",
    "# for model in models:\n",
    "#     for _ in range(warmup):\n",
    "#         inference_detector(model, img)\n",
    "\n",
    "\n",
    "gpu_workers = [\n",
    "    Thread(target=single_inference_detector, args=[model, data_q, result_q])\n",
    "             for model in models]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start data loaders\n",
    "for worker in data_workers:\n",
    "    worker.start()\n",
    "# %time img_q.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 6s, sys: 1min 49s, total: 13min 56s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "# wait for data queue\n",
    "time.sleep(1)\n",
    "\n",
    "# start threads\n",
    "for worker in gpu_workers:\n",
    "    worker.start()\n",
    "# wait to finish\n",
    "%time data_q.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_q.qsize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
